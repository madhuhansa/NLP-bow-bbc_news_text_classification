{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bbba4de",
   "metadata": {},
   "source": [
    "Step 1: Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a421170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3f028",
   "metadata": {},
   "source": [
    "Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76bc8d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget to set scene for election\\n \\n Gordon B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army chiefs in regiments decision\\n \\n Militar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Howard denies split over ID cards\\n \\n Michael...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observers to monitor UK election\\n \\n Minister...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kilroy names election seat target\\n \\n Ex-chat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Budget to set scene for election\\n \\n Gordon B...      0\n",
       "1  Army chiefs in regiments decision\\n \\n Militar...      0\n",
       "2  Howard denies split over ID cards\\n \\n Michael...      0\n",
       "3  Observers to monitor UK election\\n \\n Minister...      0\n",
       "4  Kilroy names election seat target\\n \\n Ex-chat...      0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_file.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04734dbd",
   "metadata": {},
   "source": [
    "Step03: Understand Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a729a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d03613df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    511\n",
       "4    510\n",
       "0    417\n",
       "2    401\n",
       "3    386\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f606b40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     0\n",
       "Label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "357522de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376ce1c",
   "metadata": {},
   "source": [
    "Step 4: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9e85e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    505\n",
       "4    503\n",
       "0    403\n",
       "3    369\n",
       "2    347\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df['Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ff40e",
   "metadata": {},
   "source": [
    "Step 5: pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad814fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34968936",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be94b962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thor eat pizza'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Thor ate pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68a7a2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget to set scene for election\\n \\n Gordon B...</td>\n",
       "      <td>0</td>\n",
       "      <td>budget set scene election \\n \\n  Gordon Brown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army chiefs in regiments decision\\n \\n Militar...</td>\n",
       "      <td>0</td>\n",
       "      <td>army chief regiment decision \\n \\n  military c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Howard denies split over ID cards\\n \\n Michael...</td>\n",
       "      <td>0</td>\n",
       "      <td>Howard deny split ID card \\n \\n  Michael Howar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observers to monitor UK election\\n \\n Minister...</td>\n",
       "      <td>0</td>\n",
       "      <td>observer monitor UK election \\n \\n  Ministers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kilroy names election seat target\\n \\n Ex-chat...</td>\n",
       "      <td>0</td>\n",
       "      <td>kilroy name election seat target \\n \\n  ex cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  Budget to set scene for election\\n \\n Gordon B...      0   \n",
       "1  Army chiefs in regiments decision\\n \\n Militar...      0   \n",
       "2  Howard denies split over ID cards\\n \\n Michael...      0   \n",
       "3  Observers to monitor UK election\\n \\n Minister...      0   \n",
       "4  Kilroy names election seat target\\n \\n Ex-chat...      0   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  budget set scene election \\n \\n  Gordon Brown ...  \n",
       "1  army chief regiment decision \\n \\n  military c...  \n",
       "2  Howard deny split ID card \\n \\n  Michael Howar...  \n",
       "3  observer monitor UK election \\n \\n  Ministers ...  \n",
       "4  kilroy name election seat target \\n \\n  ex cha...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Text'] = df['Text'].apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f8d90",
   "metadata": {},
   "source": [
    "Step 6: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8f1f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a3f43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4b167",
   "metadata": {},
   "source": [
    "Attempt 1 : Use 1-gram which is nothing but a Bag Of Words (BOW) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b4fb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "236f576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96        79\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.90      0.98      0.94        62\n",
      "           3       0.99      0.93      0.96        73\n",
      "           4       0.98      0.95      0.97       102\n",
      "\n",
      "    accuracy                           0.97       426\n",
      "   macro avg       0.96      0.97      0.96       426\n",
      "weighted avg       0.97      0.97      0.97       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 1))),       \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3209e3",
   "metadata": {},
   "source": [
    "Attempt 2 : Use 1-gram and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "367fcd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        79\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.87      0.98      0.92        62\n",
      "           3       1.00      0.81      0.89        73\n",
      "           4       0.99      0.95      0.97       102\n",
      "\n",
      "    accuracy                           0.95       426\n",
      "   macro avg       0.95      0.95      0.94       426\n",
      "weighted avg       0.96      0.95      0.95       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_1_2_gram', CountVectorizer(ngram_range = (1, 2))), \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92861ba8",
   "metadata": {},
   "source": [
    "Attempt 3 : Use 1-gram to trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f1fcab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        79\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.86      1.00      0.93        62\n",
      "           3       1.00      0.77      0.87        73\n",
      "           4       1.00      0.95      0.97       102\n",
      "\n",
      "    accuracy                           0.95       426\n",
      "   macro avg       0.94      0.94      0.94       426\n",
      "weighted avg       0.95      0.95      0.95       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_1_3_grams', CountVectorizer(ngram_range = (1, 3))),    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe53811",
   "metadata": {},
   "source": [
    "Use text pre-processing to remove stop words, punctuations and apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "841b18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = df['Cleaned_Text']\n",
    "y_cleaned = df['Label']\n",
    "\n",
    "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435999ad",
   "metadata": {},
   "source": [
    "Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ea5ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        79\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.91      0.98      0.95        62\n",
      "           3       1.00      0.92      0.96        73\n",
      "           4       0.98      0.95      0.97       102\n",
      "\n",
      "    accuracy                           0.97       426\n",
      "   macro avg       0.96      0.97      0.96       426\n",
      "weighted avg       0.97      0.97      0.97       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range=(1, 1))),       \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "# 2. Fit with X_train and y_train\n",
    "clf.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# 3. Get the predictions for X_test and store them in y_pred\n",
    "y_pred = clf.predict(X_test_cleaned)\n",
    "\n",
    "# 4. Print the classification report\n",
    "print(classification_report(y_test_cleaned, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2da78c",
   "metadata": {},
   "source": [
    "Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "865c6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        79\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.92      0.98      0.95        62\n",
      "           3       1.00      0.89      0.94        73\n",
      "           4       0.99      0.96      0.98       102\n",
      "\n",
      "    accuracy                           0.97       426\n",
      "   macro avg       0.96      0.96      0.96       426\n",
      "weighted avg       0.97      0.97      0.97       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range=(1, 2))),       \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "# 2. Fit with X_train and y_train\n",
    "clf.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# 3. Get the predictions for X_test and store them in y_pred\n",
    "y_pred = clf.predict(X_test_cleaned)\n",
    "\n",
    "# 4. Print the classification report\n",
    "print(classification_report(y_test_cleaned, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424e77a",
   "metadata": {},
   "source": [
    "Attempt 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a3150d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        79\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.90      0.98      0.94        62\n",
      "           3       1.00      0.86      0.93        73\n",
      "           4       0.99      0.96      0.98       102\n",
      "\n",
      "    accuracy                           0.96       426\n",
      "   macro avg       0.96      0.96      0.96       426\n",
      "weighted avg       0.97      0.96      0.96       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),       \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "# 2. Fit with X_train and y_train\n",
    "clf.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# 3. Get the predictions for X_test and store them in y_pred\n",
    "y_pred = clf.predict(X_test_cleaned)\n",
    "\n",
    "# 4. Print the classification report\n",
    "print(classification_report(y_test_cleaned, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
